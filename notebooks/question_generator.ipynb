{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtlYnTPRxzNF/6cGN8uh9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BNkosi/odin/blob/master/notebooks/question_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cku4dWPHh-BE"
      },
      "source": [
        "# !pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ4UT7RVVAWn"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE9rs_hOOZRz"
      },
      "source": [
        "class QuestionGenerator:\n",
        "    def __init__(self, doc_dir: str = '/content/training_data', question_dir: str = 'data/training/questions.json', max_length: int=64):\n",
        "        self.doc_dir = doc_dir\n",
        "        self.qu_dir = question_dir\n",
        "\n",
        "    def list_docs(self):\n",
        "        for filename in os.listdir(self.doc_dir):\n",
        "            print(filename)\n",
        "\n",
        "    def load_models(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "        self.model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "\n",
        "    def generate_qs(self):\n",
        "        # Fetch documents\n",
        "        self.docs=list()\n",
        "        self.questions={\n",
        "            \"question\": list(),\n",
        "            \"title\": list(),\n",
        "            \"url\": list(),\n",
        "            \"context\": list(),\n",
        "        }\n",
        "        for filename in os.listdir(self.doc_dir):\n",
        "            if filename.endswith(\".txt\"): \n",
        "                with open(str(self.doc_dir+\"/\"+filename), mode = 'r', encoding='utf-8') as doc:\n",
        "                    text = doc.read()\n",
        "                    text = self.clean_website_text(text)\n",
        "                    self.docs.append({\"title\": filename, \"text\": text})\n",
        "                    doc.close()\n",
        "            else:\n",
        "                continue\n",
        "        \n",
        "        # Generate list of training questions\n",
        "        # for each document\n",
        "        for doc in range(len(self.docs)):\n",
        "            # get data\n",
        "            title = self.docs[doc][\"title\"]\n",
        "            text = self.docs[doc][\"text\"]\n",
        "            # text = self.sequence_limiter(text)\n",
        "            link = [line for line in text.split(\"\\n\") if line.startswith(\"https\")]\n",
        "            long_line = \" \".join([line for line in text.split(\"\\n\")])\n",
        "            sentences = [line for line in long_line.split(\".\") if line.startswith(\"https\")==False or line != \"\" or line!= \" \"]\n",
        "    \n",
        "            for i in range(len(sentences)):\n",
        "                for word in sentences[i].split():\n",
        "                    question = self.get_question(word, sentences[i])\n",
        "                    question = re.sub('question: ', '', question)\n",
        "                    print(f\"{question}\")\n",
        "                    self.questions[\"question\"].append(question)\n",
        "                    self.questions[\"title\"].append(title)\n",
        "                    self.questions[\"url\"].append(link)\n",
        "                    self.questions[\"context\"].append(text)\n",
        "        # Save questions to json\n",
        "        with open(self.qu_dir, 'w') as fp:\n",
        "            json.dump(self.questions, fp)\n",
        "            fp.close()\n",
        "            \n",
        "\n",
        "\n",
        "    def get_question(self, answer, context, max_length=64):\n",
        "        input_text = \"answer: %s  context: %s </s>\" % (answer, context)\n",
        "        features = self.tokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "        output = self.model.generate(\n",
        "            input_ids=features['input_ids'],\n",
        "            attention_mask=features['attention_mask'],\n",
        "            max_length=max_length\n",
        "        )\n",
        "        return self.tokenizer.decode(output[0])\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_website_text(text: str()):\n",
        "        # removing lines starting with \"<\", \">\", \"=\"\n",
        "        exclude = []\n",
        "        for i in range(len(text.split(\"\\n\"))):\n",
        "            if text.split(\"\\n\")[i].startswith(\"<\"):\n",
        "                exclude.append(text.split(\"\\n\")[i])\n",
        "            elif text.split(\"\\n\")[i].startswith(\"=\"):\n",
        "                exclude.append(text.split(\"\\n\")[i])\n",
        "            elif text.split(\"\\n\")[i].startswith(\">\"):\n",
        "                exclude.append(text.split(\"\\n\")[i])\n",
        "            elif text.split(\"\\n\")[i] == \"\":\n",
        "                exclude.append(text.split(\"\\n\")[i])\n",
        "            elif text.split(\"\\n\")[i] == \" \":\n",
        "                exclude.append(text.split(\"\\n\")[i])\n",
        "        text_clean = []\n",
        "        for i in text.split(\"\\n\"):\n",
        "            if i not in exclude:\n",
        "                text_clean.append(i)\n",
        "        \n",
        "        text = \"\\n\".join(text_clean)\n",
        "        \n",
        "        # Text cleaning\n",
        "        text = re.sub(\"Jan \", \"January \", text)\n",
        "        text = re.sub(\"Feb \", \"February \", text)\n",
        "        text = re.sub(\"Mar \", \"March \", text)\n",
        "        text = re.sub(\"Apr \", \"April \", text)\n",
        "        text = re.sub(\"May \", \"May \", text)\n",
        "        text = re.sub(\"Jun \", \"June \", text)\n",
        "        text = re.sub(\"Jul \", \"July \", text)\n",
        "        text = re.sub(\"Aug \", \"August \", text)\n",
        "        text = re.sub(\"Sep \", \"September \", text)\n",
        "        text = re.sub(\"Oct \", \"October \", text)\n",
        "        text = re.sub(\"Nov \", \"November \", text)\n",
        "        text = re.sub(\"Dec \", \"December \", text)\n",
        "        text = re.sub(\"&\", \"and\", text)\n",
        "        text = re.sub(\"T�s\", \"terms\", text)\n",
        "        text = re.sub(\"C�s\", \"conditions\", text)\n",
        "        text = re.sub(\"sure�\", \"sure?\", text)\n",
        "        text = re.sub(\"�Find your tribe�\", \"Find your tribe\", text)\n",
        "        text = re.sub(\"NQF\", \"National Qualifications Framework (NQF)\", text)\n",
        "        text = re.sub(\"team�s\", \"team's\", text)\n",
        "        text = re.sub(\"We're\", \"We are\", text)\n",
        "        text = re.sub(\"we're\", \"we are\", text)\n",
        "        text = re.sub(\"AWS\", \"Amazon Web Services\", text)\n",
        "        text = re.sub(\"Amazon's\", \"Amazon\", text)\n",
        "        text = re.sub(\"EC2\", \"Elastic Cloud Compute\", text)\n",
        "        text = re.sub(\"EBS\", \"Elastic Block Store\", text)\n",
        "        text = re.sub(\"EFS\", \"Elastic File Store\", text)\n",
        "        text = re.sub(\"S3\", \"Simple Storage, Service\", text)\n",
        "        text = re.sub(\"RDS\", \"Relational Database Service\", text)\n",
        "        text = re.sub(\"VPC\", \"Virtual Private Cloud\", text)\n",
        "        text = re.sub(\"Services\", \"\", text)\n",
        "        text = re.sub(\"IAM\", \"Identity and Access Management\", text)\n",
        "        text = re.sub(\"CSIR\", \"Council for Scientific and Industrial Research\", text)\n",
        "        text = re.sub(\"2/3\", \"2 to 3\", text)\n",
        "        text = re.sub(\"NLP\", \"Natural Language Processing\", text)\n",
        "        text = re.sub(\"JanuarydeWet\", \"January de Wet\", text)\n",
        "        text = re.sub(\"UK\", \"United Kingdom\", text)\n",
        "        text = re.sub(\"fin-tech\", \"financial services technology\", text)\n",
        "        text = re.sub(\"�ll\", \" will\", text)\n",
        "        text = re.sub(\"n�t\", \" not\", text)\n",
        "        text = re.sub(\"1:1\", \"one-on-one\", text)\n",
        "        text = re.sub(\"we�ve\", \"we have\", text)\n",
        "        text = re.sub(\"We�ve\", \"we have\", text)\n",
        "        text = re.sub(\"We�re\", \"We are\", text)\n",
        "        text = re.sub(\"we�re\", \"we are\", text)\n",
        "        text = re.sub(\"/\", \" or \", text)\n",
        "        text = re.sub(\"API�s\", \"application programming interfaces\", text)\n",
        "        text = re.sub(\"ANN�s\", \"Artificial Neural Networks\", text)\n",
        "        text = re.sub(\"CNN�s\", \"Convolutional Neural Networks\", text)\n",
        "        text = re.sub(\"RNN�s\", \"Recurrent Neural Networks\", text)\n",
        "        text = re.sub(\"it�s\", \"it is\", text)\n",
        "        text = re.sub(\"\\t\", \" \", text)\n",
        "        text = re.sub(\"CAs\", \"Chartered Accountants\", text)\n",
        "        text = re.sub(\"CA's\", \"Chartered Accountant's\", text)\n",
        "        text = re.sub(\"An innovate\", \"An innovative\", text)\n",
        "        text = re.sub(\"it's\", \"it is\", text)\n",
        "        text = re.sub(\"It's\", \"It is\", text)\n",
        "        text = re.sub(\"don't\", \"do not\", text)\n",
        "        text = re.sub(\"There's\", \"There is\", text)\n",
        "        text = re.sub(\"you'll\", \"you will\", text)\n",
        "        text = re.sub(\"you're\", \"you are\", text)\n",
        "        text = re.sub(\"We've\", \"We have\", text)\n",
        "        text = re.sub(\"we've\", \"we have\", text)\n",
        "        text = re.sub(\"you�re\", \"you are\", text)\n",
        "        text = re.sub(\"�CTC�\", \"(CTC)\", text)\n",
        "        text = re.sub(\"�Qualifying Position�\", '\"Qualifying Position\"', text)\n",
        "        text = re.sub(\".Explore\", \"Explore\", text)\n",
        "        text = re.sub(\"Explore�s\", \"Explore's\", text)\n",
        "        text = re.sub(\"you�ve\", \"you have\", text)\n",
        "        text = re.sub(\"�TWOE�\", \"(TWOE)\", text)\n",
        "        text = re.sub(\"coaches�\", \"coaches'\", text)\n",
        "        text = re.sub(\"IRP5�s\", \"IRP5's\", text)\n",
        "        text = re.sub(\"sill\", \"will\", text)\n",
        "        text = re.sub(\"we'll\", \"we will\", text)\n",
        "        text = re.sub(\"�ve\", \" have\", text)\n",
        "        text = re.sub(\"It�s been\", \"It has been\", text)\n",
        "        text = re.sub(\"It�s a\", \"It is a\", text)\n",
        "        text = re.sub(\"It�s open\", \"It is open\", text)\n",
        "        text = re.sub(\"It�s used\", \"It is used\", text)\n",
        "        text = re.sub(\"It�s free\", \"It is free\", text)\n",
        "        text = re.sub(\"It�s very\", \"It is very\", text)\n",
        "        text = re.sub(\"SVM�s\", \"Support Vector Machines\", text)\n",
        "        text = re.sub(\"I�m\", \" I am\", text)\n",
        "        text = re.sub(\"country�s\", \"country's\", text)\n",
        "        text = re.sub(\"projects�helping\", \"projects - helping\", text)\n",
        "        text = re.sub(\"EXPLORE�s\", \"EXPLORE's\", text)\n",
        "        text = re.sub(\"That�s\", \"That is\", text)\n",
        "        text = re.sub(\"month�s\", \"month's\", text)\n",
        "        text = re.sub(\"South African�s\", \"South Africans\", text)\n",
        "        text = re.sub(\"Data Scientist�s\", \"Data Scientist's\", text)\n",
        "        text = re.sub(\"�Data Scientist�\", '\"Data Scientist\"', text)\n",
        "        text = re.sub(\"�sexiest profession of the 21st Century�\", '\"sexiest profession of the 21st Century\"', text)\n",
        "        text = re.sub(\"email�protected\", \"email protected\", text)\n",
        "        text = re.sub(\"python�s\", \"Python's\", text)\n",
        "        text = re.sub(\"he�s\", \"he is\", text)\n",
        "        text = re.sub(\"�Reading�s\", \"Reading's\", text)\n",
        "        text = re.sub(\"1,000�s\", \"thousands\", text)\n",
        "        text = re.sub(\"They�re\", \"They are\", text)\n",
        "        text = re.sub(\"they�re\", \"they are\", text)\n",
        "        text = re.sub(\"customer�s\", \"customer's\", text)\n",
        "        text = re.sub('\\\\\"', \"\", text)\n",
        "        text = re.sub(\" � \", \" - \", text)\n",
        "        text = re.sub(\"�\", \"\", text)    \n",
        "        # Join text into one line\n",
        "        text = \" \".join(text.split('\\n'))\n",
        "        return text\n",
        "\n",
        "    # @staticmethod\n",
        "    # def sequence_limiter(text):\n",
        "    #     text = text.split(\". \")\n",
        "    #     text = \". \".join([sent if len(sent) <=512 else sent[:-512] for sent in text])\n",
        "    #     return text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlJtY6jnOb93",
        "outputId": "fcf63d48-2f0a-4e91-b8f2-fb50497c1ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generator = QuestionGenerator()\n",
        "generator.list_docs()\n",
        "generator.load_models()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explore_alumni_hire-explorer.txt\n",
            "explore_contact.txt\n",
            "explore_about-us_our-courses.txt\n",
            "explore_alumni_student-reviews.txt\n",
            "explore_about-us_our-values.txt\n",
            "explore_.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFuzghG7ozv_",
        "outputId": "953f68eb-37bf-4d96-b584-f781bcc4e113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generator.generate_qs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_t5.py:177: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "What is the URL of explore-datascience?\n",
            "What is the name of the explore-datascience project?\n",
            "What is the name of the explore-datascience project?\n",
            "What is the name of the project that is being investigated?\n",
            "What is another name for alumni?\n",
            "What is the name of the alumni who can help us find you?\n",
            "Who is an employee of the Net?\n",
            "What is the name of the alumni who can help us find you?\n",
            "Who is another name for alumni?\n",
            "What type of courses are offered?\n",
            "What do we offer?\n",
            "What type of time are our courses?\n",
            "What is the time frame of our online courses?\n",
            "Where are the courses offered?\n",
            "Where are the courses offered?\n",
            "What is the main difference between a full time on campus and part time online courses?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "Part time Online Qualifications Data Engineering Data Analytics Business Intelligence NANO-Qualifications Advanced Visualisation Data Visualisation Machine Learning Data Pipelines And Automation Data Science For Analysts See all courses Short Courses What type of Online Qualifications?\n",
            "What is the time frame of our online courses?\n",
            "Where do you find the Data Science Part time courses?\n",
            "What is the main difference between a full time on campus and part time online courses?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "What is the subject of the online courses?\n",
            "What is the main field of study in Data Engineering?\n",
            "What type of Intelligence does NANO-Qualifications offer?\n",
            "What is the business of NANO-Qualifications?\n",
            "What is the name of the qualification that is offered at a part time online college?\n",
            "What type of Visualisation is required?\n",
            "What is the advanced skill in Data Science?\n",
            "What is the subject of the online courses?\n",
            "What is the advanced skill in Data Science?\n",
            "What type of learning is NANO-Qualifications?\n",
            "What is the purpose of EXPLORER courses?\n",
            "What is the subject of the online courses?\n",
            "What type of data do you build?\n",
            "What is the main difference between a full time online and a part time online course?\n",
            "What is the field of data science that we teach?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "What is the purpose of the PART-TIME Online DIGITAL SKILLS?\n",
            "Who is Data Science for?\n",
            "What are the courses for Short Courses?\n",
            "What are the courses that are available for short courses?\n",
            "What do alumni students see?\n",
            "What type of courses are available?\n",
            "What do we offer?\n",
            "What type of Online courses are offered?\n",
            "Where do you find the Data Science Part time courses?\n",
            "What type of skills are available in part time online courses?\n",
            "What is a part time online course called?\n",
            "What kind of skills do industry leaders seek out EXPLORER to boost their capacity?\n",
            "What is a part time online course?\n",
            "What is the most common digital skill for Data Science?\n",
            "What is the purpose of the PART-TIME Online DIGITAL SKILLS?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "What is the language used for Data Science?\n",
            "What is the purpose of the PART-TIME Online DIGITAL SKILLS?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "What type of Visualisation is required?\n",
            "What is the main skill of Python for Data Science?\n",
            "What is the advanced skill in Data Science?\n",
            "What type of Visualisation is required?\n",
            "What is the term for unsupervised learning?\n",
            "What type of learning is required for Data Science Cloud Computing?\n",
            "What is the purpose of EXPLORER courses?\n",
            "What is the first step in learning about data science?\n",
            "What is the purpose of the EXPLORER course?\n",
            "What is the subject of the online courses?\n",
            "What field of study is part time online?\n",
            "What type of computing is Data Warehousing?\n",
            "What is the main field of data science?\n",
            "What is the subject of the online courses?\n",
            "What is a major area of data science?\n",
            "What is the main difference between a full time online and a part time online course?\n",
            "What type of lake is Data Automation?\n",
            "What is the subject of the online courses?\n",
            "What is the field of data science that we teach?\n",
            "Who is an employee of Hire-explorer?\n",
            "What type of review does Hire an EXPLORER have?\n",
            "What type of feedback do alumni students give to hire-explorer?\n",
            "What is the name of the company that hires EXPLORER?\n",
            "Who can you hire to be an EXPLORER?\n",
            "What do industry leaders seek out to boost their digital capacity?\n",
            "What is the name of the company that hires an EXPLORER?\n",
            "Who is the EXPLORER?\n",
            "What is the name of the company that provides EXPLORER training?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5y1LDGfo3dH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}